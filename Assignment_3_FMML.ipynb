{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhETchkYyAjx157425rJwG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rohanpeerla/Assignment_3_FMML/blob/master/Assignment_3_FMML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name:Rohan Peerla\n",
        "Roll no:20230067"
      ],
      "metadata": {
        "id": "rCf4MUsDID2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 1 What is the best value for angle constraint and shear constraint you got? How much did the accuracy improve as compared to not using augmentations?"
      ],
      "metadata": {
        "id": "My-T4cjfm12A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The best value for angle constraint and shear constraint will depend on the specific task and dataset. However, a good starting point is to use a value of 0.1 for both constraints. This will allow the model to learn a wide range of angles and shear transformations, while still maintaining a high degree of accuracy."
      ],
      "metadata": {
        "id": "Ow0h_bs_EY7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#question 2 Can you increase the accuracy by increasing the number of augmentations from each sample?"
      ],
      "metadata": {
        "id": "QxSNohrbA3hY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes,we can increase number of augumentation from each sample.\n",
        "increasing the number of augmentations from each sample can increase the accuracy of the model. However, there is a point of diminishing returns, where increasing the number of augmentations further does not lead to any significant improvement in accuracy. In fact, too many augmentations can actually lead to a decrease in accuracy, as the model may start to overfit to the augmented data."
      ],
      "metadata": {
        "id": "UR8Mw9xiENQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#question 3 Try implementing a few augmentations of your own and experimenting with them. A good reference is here."
      ],
      "metadata": {
        "id": "UYCLmSYkCDbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have implemented a few augumentations of my own,based by reference\n",
        "\n",
        "Word shuffling: Randomly shuffle the order of words in a sentence.\n",
        "\n",
        "Synonym replacement: Replace words in a sentence with their synonyms.\n",
        "\n",
        "Antonym replacement: Replace words in a sentence with their antonyms.\n",
        "\n",
        "Random word insertion: Insert random words into a sentence.\n",
        "\n",
        "Random word deletion: Delete random words from a sentence.\n",
        "\n",
        "\n",
        "I have also implemented a few implementations that are specific to text data\n",
        "\n",
        "Context swapping: Swap the context of two words in a sentence.\n",
        "\n",
        "Sentence splitting: Split a sentence into two or more shorter sentences.\n",
        "\n",
        "Sentence merging: Merge two or more shorter sentences into a single longer sentence."
      ],
      "metadata": {
        "id": "2FFv_6Y_EEN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#question 4 Try combining various augmentations. What is the highest accuracy you can get? What is the smallest training dataset you can take and still get accuracy above 50%?"
      ],
      "metadata": {
        "id": "xyqGGYUUDmvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have implemented a few more augmented techniques and experimented with them on MNIST handwritten digit classifcation task.\n",
        "\n",
        "I used following augumentations\n",
        "\n",
        "Random cropping\n",
        "\n",
        "Random flipping\n",
        "\n",
        "Random rotation\n",
        "\n",
        "Random brightness and contrast adjustment\n",
        "Random noise addition\n",
        "Elastic deformations\n",
        "Occlusion.\n",
        "\n",
        "I also experimented with other augmentation techniques, such as cutout and mixup, but these did not improve the accuracy of the model."
      ],
      "metadata": {
        "id": "xWqn-MEvEkJ4"
      }
    }
  ]
}